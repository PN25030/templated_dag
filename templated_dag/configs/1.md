To create a Dataplex data quality scan on a BigQuery table located in the tenant project while running the scan in the service project, use the following gcloud command:

Step 1: Set required environment variables

export TENANT_PROJECT_ID=<your-tenant-project-id>
export SERVICE_PROJECT_ID=<your-service-project-id>
export LOCATION=<region>  # e.g., us-central1
export LAKE_NAME=<your-dataplex-lake>
export DATASET=<your-bq-dataset>
export TABLE=<your-bq-table>
export SCAN_NAME=<your-scan-name>

Step 2: Create the Dataplex scan

gcloud dataplex data-scans create $SCAN_NAME \
    --project=$SERVICE_PROJECT_ID \
    --location=$LOCATION \
    --lake=$LAKE_NAME \
    --data-scan-type=DATA_QUALITY \
    --data-source="bigquery://projects/$TENANT_PROJECT_ID/datasets/$DATASET/tables/$TABLE" \
    --display-name="BQ Table Scan" \
    --description="Data quality scan on BigQuery table" \
    --execution-spec-trigger-type=ON_DEMAND

Step 3: Run the scan (optional if you want immediate execution)

gcloud dataplex data-scans run $SCAN_NAME \
    --project=$SERVICE_PROJECT_ID \
    --location=$LOCATION

Ensure:
	1.	The Dataplex service account in the service project has BigQuery Data Viewer access on the table in the tenant project.
	2.	Cross-project permissions and Dataplex roles (roles/dataplex.admin, roles/dataplex.viewer) are correctly assigned.

Would you like to schedule the scan or define custom rules?